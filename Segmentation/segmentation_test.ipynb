{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeOs6jOAQJ2J",
        "outputId": "0b11f4b1-5db1-4313-82ff-1c8f2e1be59e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: paramparse in /usr/local/lib/python3.7/dist-packages (1.7.6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import timeit\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from skimage.draw import polygon\n",
        "import sys\n",
        "!pip install paramparse\n",
        "import paramparse\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BnatBoZDQJ2L"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "        \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "def segmentate(images):\n",
        "    \"\"\"\n",
        "    :param np.ndarray images: N x 12288 array containing N 64x64x3 images flattened into vectors\n",
        "    :return: np.ndarray\n",
        "    \"\"\"\n",
        "    N = images.shape[0]\n",
        "    # pred_seg: Your predicted segmentation for the image, shape [N, 4096]\n",
        "    pred_seg = np.empty((N, 4096), dtype=np.int32)\n",
        "    # add your code here to fill in pred_seg\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    images = images.reshape([images.shape[0], 64, 64, 3])\n",
        "    images = np.transpose(images, (0, 3, 1, 2))\n",
        "    model = UNet(3,11).to(device)\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive/', force_remount=True)\n",
        "    model.load_state_dict(torch.load(\"/content/gdrive/My Drive/visual_recognition_data/checkpoint_15.pth\", map_location=device))\n",
        "    model = model.to(device)\n",
        "    \n",
        "    for i in range(N):\n",
        "        image = torch.as_tensor(images[i]).float()\n",
        "        logit = model(image.to(device).view(-1,3,64,64))\n",
        "        pred = logit.argmax(1).view(-1).long().cpu().numpy()\n",
        "        pred_seg[i,:] = pred\n",
        "        if i % 100 == 0:\n",
        "            print('Evaluating: [{}/{} ({:.0f}%)]\\n'.format(i, N, (i/N*100)))\n",
        "    \n",
        "    \n",
        "    return pred_seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7UQdytNLQJ2M"
      },
      "outputs": [],
      "source": [
        "def compute_seg(pred, gt):\n",
        "    # pred value should be from 0 to 10, where 10 is the background.\n",
        "    # accuracy is calculated for only non background pixels.\n",
        "    assert pred.shape == gt.shape\n",
        "    mask = gt != 10\n",
        "    return (pred[mask] == gt[mask]).astype(int).sum() / gt[mask].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YiFl7HMnQJ2N"
      },
      "outputs": [],
      "source": [
        "class A8_Params:\n",
        "    def __init__(self):\n",
        "        # self.prefix = \"test\"\n",
        "        self.prefix = \"valid\"\n",
        "        # self.prefix = \"train\"\n",
        "        self.vis = 0\n",
        "        self.vis_size = (300, 300)\n",
        "        self.show_pred = 1\n",
        "        self.speed_thresh = 10\n",
        "        self.seg_thresh = (0.7, 0.98)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aYSKnl2WQJ2N"
      },
      "outputs": [],
      "source": [
        "def compute_score(res, thresh):\n",
        "    min_thres, max_thres = thresh\n",
        "    if res < min_thres:\n",
        "        score = 0.0\n",
        "    elif res > max_thres:\n",
        "        score = 100.0\n",
        "    else:\n",
        "        score = float(res - min_thres) / (max_thres - min_thres) * 100\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuImj2p3QJ2O",
        "outputId": "060f00ae-f4f1-46ca-8db7-4f37ee282424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "running on 5000 valid images\n",
            "Mounted at /content/gdrive/\n",
            "Evaluating: [0/5000 (0%)]\n",
            "\n",
            "Evaluating: [100/5000 (2%)]\n",
            "\n",
            "Evaluating: [200/5000 (4%)]\n",
            "\n",
            "Evaluating: [300/5000 (6%)]\n",
            "\n",
            "Evaluating: [400/5000 (8%)]\n",
            "\n",
            "Evaluating: [500/5000 (10%)]\n",
            "\n",
            "Evaluating: [600/5000 (12%)]\n",
            "\n",
            "Evaluating: [700/5000 (14%)]\n",
            "\n",
            "Evaluating: [800/5000 (16%)]\n",
            "\n",
            "Evaluating: [900/5000 (18%)]\n",
            "\n",
            "Evaluating: [1000/5000 (20%)]\n",
            "\n",
            "Evaluating: [1100/5000 (22%)]\n",
            "\n",
            "Evaluating: [1200/5000 (24%)]\n",
            "\n",
            "Evaluating: [1300/5000 (26%)]\n",
            "\n",
            "Evaluating: [1400/5000 (28%)]\n",
            "\n",
            "Evaluating: [1500/5000 (30%)]\n",
            "\n",
            "Evaluating: [1600/5000 (32%)]\n",
            "\n",
            "Evaluating: [1700/5000 (34%)]\n",
            "\n",
            "Evaluating: [1800/5000 (36%)]\n",
            "\n",
            "Evaluating: [1900/5000 (38%)]\n",
            "\n",
            "Evaluating: [2000/5000 (40%)]\n",
            "\n",
            "Evaluating: [2100/5000 (42%)]\n",
            "\n",
            "Evaluating: [2200/5000 (44%)]\n",
            "\n",
            "Evaluating: [2300/5000 (46%)]\n",
            "\n",
            "Evaluating: [2400/5000 (48%)]\n",
            "\n",
            "Evaluating: [2500/5000 (50%)]\n",
            "\n",
            "Evaluating: [2600/5000 (52%)]\n",
            "\n",
            "Evaluating: [2700/5000 (54%)]\n",
            "\n",
            "Evaluating: [2800/5000 (56%)]\n",
            "\n",
            "Evaluating: [2900/5000 (58%)]\n",
            "\n",
            "Evaluating: [3000/5000 (60%)]\n",
            "\n",
            "Evaluating: [3100/5000 (62%)]\n",
            "\n",
            "Evaluating: [3200/5000 (64%)]\n",
            "\n",
            "Evaluating: [3300/5000 (66%)]\n",
            "\n",
            "Evaluating: [3400/5000 (68%)]\n",
            "\n",
            "Evaluating: [3500/5000 (70%)]\n",
            "\n",
            "Evaluating: [3600/5000 (72%)]\n",
            "\n",
            "Evaluating: [3700/5000 (74%)]\n",
            "\n",
            "Evaluating: [3800/5000 (76%)]\n",
            "\n",
            "Evaluating: [3900/5000 (78%)]\n",
            "\n",
            "Evaluating: [4000/5000 (80%)]\n",
            "\n",
            "Evaluating: [4100/5000 (82%)]\n",
            "\n",
            "Evaluating: [4200/5000 (84%)]\n",
            "\n",
            "Evaluating: [4300/5000 (86%)]\n",
            "\n",
            "Evaluating: [4400/5000 (88%)]\n",
            "\n",
            "Evaluating: [4500/5000 (90%)]\n",
            "\n",
            "Evaluating: [4600/5000 (92%)]\n",
            "\n",
            "Evaluating: [4700/5000 (94%)]\n",
            "\n",
            "Evaluating: [4800/5000 (96%)]\n",
            "\n",
            "Evaluating: [4900/5000 (98%)]\n",
            "\n",
            "Segmentation Accuracy: 0.947\n",
            "Test time: 41.503 seconds\n",
            "Test speed: 120.473 images / second\n",
            "Overall Score: 88.204\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    params = A8_Params()\n",
        "    prefix = params.prefix\n",
        "    drive.mount('/content/gdrive/', force_remount=True)\n",
        "    images = np.load(\"/content/gdrive/My Drive/visual_recognition_data/\" + prefix + \"_X.npy\")\n",
        "    gt_segs = np.load(\"/content/gdrive/My Drive/visual_recognition_data/\" + prefix + \"_seg.npy\")\n",
        "    n_images = images.shape[0]\n",
        "    print(f'running on {n_images} {prefix} images')\n",
        "    start_t = timeit.default_timer()\n",
        "    pred_segs = segmentate(images)\n",
        "    end_t = timeit.default_timer()\n",
        "    test_time = end_t - start_t\n",
        "    assert test_time > 0, \"test_time cannot be 0\"\n",
        "    test_speed = float(n_images) / test_time\n",
        "    seg = compute_seg(pred_segs, gt_segs)\n",
        "    seg_score = compute_score(seg, params.seg_thresh)\n",
        "    if test_speed < params.speed_thresh:\n",
        "        overall_score = 0\n",
        "    else:\n",
        "        overall_score = seg_score\n",
        "    print(f\"Segmentation Accuracy: {seg:.3f}\")\n",
        "    print(f\"Test time: {test_time:.3f} seconds\")\n",
        "    print(f\"Test speed: {test_speed:.3f} images / second\")\n",
        "    print(f\"Overall Score: {overall_score:.3f}\")\n",
        "    \n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
