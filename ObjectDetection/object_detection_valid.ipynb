{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_GTtfSTrK8",
        "outputId": "6e0e8dc0-3d43-4411-9d11-c1ef3f3ab45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "udajAUAvTrK_"
      },
      "outputs": [],
      "source": [
        "def conv_batch(in_num, out_num, kernel_size=3, padding=1, stride=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_num, out_num, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(out_num),\n",
        "        nn.LeakyReLU())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBdjDg5bTrK_"
      },
      "source": [
        "Residual block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HgI_l5duTrLA"
      },
      "outputs": [],
      "source": [
        "class DarkResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(DarkResidualBlock, self).__init__()\n",
        "        reduced_channels = int(in_channels/2)\n",
        "        self.layer1 = conv_batch(in_channels, reduced_channels, kernel_size=1, padding=0)\n",
        "        self.layer2 = conv_batch(reduced_channels, in_channels)\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out += residual\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KDbrzOGwTrLA"
      },
      "outputs": [],
      "source": [
        "class Darknet53(nn.Module):\n",
        "    def __init__(self, block, num_classes):\n",
        "        super(Darknet53, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = conv_batch(3, 32)\n",
        "        self.conv2 = conv_batch(32, 64, stride=2)\n",
        "        self.residual_block1 = self.make_layer(block, in_channels=64, num_blocks=1)\n",
        "        self.conv3 = conv_batch(64, 128, stride=2)\n",
        "        self.residual_block2 = self.make_layer(block, in_channels=128, num_blocks=2)\n",
        "        self.conv4 = conv_batch(128, 256, stride=2)\n",
        "        self.residual_block3 = self.make_layer(block, in_channels=256, num_blocks=8)\n",
        "        self.conv5 = conv_batch(256, 512, stride=2)\n",
        "        self.residual_block4 = self.make_layer(block, in_channels=512, num_blocks=8)\n",
        "        self.conv6 = conv_batch(512, 1024, stride=2)\n",
        "        self.residual_block5 = self.make_layer(block, in_channels=1024, num_blocks=4)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, self.num_classes)\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.residual_block1(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.residual_block2(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.residual_block3(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.residual_block4(out)\n",
        "        out = self.conv6(out)\n",
        "        out = self.residual_block5(out)\n",
        "        out = self.global_avg_pool(out)\n",
        "        out = out.view(-1, 1024)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "    def make_layer(self, block, in_channels, num_blocks):\n",
        "        layers = []\n",
        "        for i in range(0, num_blocks):\n",
        "            layers.append(block(in_channels))\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LdCNs-55TrLB"
      },
      "outputs": [],
      "source": [
        "def darknet53(num_classes):\n",
        "    return Darknet53(DarkResidualBlock, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqC-vitjTrLB"
      },
      "source": [
        "Modified predict(num_classes) function for DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9M1L1Gg9TrLC"
      },
      "outputs": [],
      "source": [
        "class Darknet:\n",
        "    def __init__(self,pth):\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "        print(self.device)\n",
        "        model = darknet53(28)\n",
        "        model.load_state_dict(torch.load(pth, map_location=self.device))\n",
        "        self.Darknet53 = model.to(self.device)\n",
        "    def predict(self,image):\n",
        "        # Set for eval mode, require grad = False\n",
        "        self.Darknet53.eval()\n",
        "        gray = image.reshape(64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            gray_tensor = torch.from_numpy(gray.astype(np.float32) / 255.).permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
        "            # Onehot vector of size 28 for the output layer, 10 for first digit, 10 for secon digit, and 8 for the bbox\n",
        "            oh = self.Darknet53(gray_tensor)\n",
        "            oh_class = oh[:, :20].contiguous().view(-1, 10)\n",
        "            oh_box = oh[:, 20:]\n",
        "\n",
        "            # Sort the tensor by ascending order\n",
        "            pred_class = oh_class.argmax(1).cpu().numpy()\n",
        "            pred_box = oh_box.long().cpu().numpy()[0].reshape(2,4)\n",
        "        return pred_class,pred_box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IepiZ7BOTrLC"
      },
      "outputs": [],
      "source": [
        "def classify_and_detect(images):\n",
        "    \"\"\"\n",
        "    :param np.ndarray images: N x 4096 array containing N 64x64 images flattened into vectors\n",
        "    :return: np.ndarray, np.ndarray\n",
        "    \"\"\"\n",
        "    N = images.shape[0]\n",
        "\n",
        "    # pred_class: Your predicted labels for the 2 digits, shape [N, 2]\n",
        "    pred_class = np.empty((N, 2), dtype=np.int32)\n",
        "    # pred_bboxes: Your predicted bboxes for 2 digits, shape [N, 2, 4]\n",
        "    pred_bboxes = np.empty((N, 2, 4), dtype=np.float64)\n",
        "\n",
        "    # add your code here to fill in pred_class and pred_bboxes\n",
        "    model = Darknet(\"/content/gdrive/My Drive/visual_recognition_data/checkpoint_32.pth\")\n",
        "    for i in range(N):\n",
        "        label,box=model.predict(images[i,:])\n",
        "        box[0,2] = box[0,0] + 28\n",
        "        box[0,3] = box[0,1] + 28\n",
        "        box[1,2] = box[1,0] + 28\n",
        "        box[1,3] = box[1,1] + 28\n",
        "        pred_class[i,:]=label\n",
        "        pred_bboxes[i,:]=box\n",
        "        if i % 100 == 0:\n",
        "            print('Evaluating: [{}/{} ({:.0f}%)]\\n'.format(i, N, (i/N*100)))\n",
        "    return pred_class, pred_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KqJVNUZvTrLC"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "from skimage.draw import polygon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lRtovIHKTrLD"
      },
      "outputs": [],
      "source": [
        "def resize_ar(src_img, width=0, height=0, return_factors=False,\n",
        "              placement_type=0):\n",
        "    import cv2\n",
        "    src_height, src_width, n_channels = src_img.shape\n",
        "    src_aspect_ratio = float(src_width) / float(src_height)\n",
        "    if width <= 0 and height <= 0:\n",
        "        raise AssertionError('Both width and height cannot be zero')\n",
        "    elif height <= 0:\n",
        "        height = int(width / src_aspect_ratio)\n",
        "    elif width <= 0:\n",
        "        width = int(height * src_aspect_ratio)\n",
        "    aspect_ratio = float(width) / float(height)\n",
        "    if src_aspect_ratio == aspect_ratio:\n",
        "        dst_width = src_width\n",
        "        dst_height = src_height\n",
        "        start_row = start_col = 0\n",
        "    elif src_aspect_ratio > aspect_ratio:\n",
        "        dst_width = src_width\n",
        "        dst_height = int(src_width / aspect_ratio)\n",
        "        start_row = int((dst_height - src_height) / 2.0)\n",
        "        if placement_type == 0:\n",
        "            start_row = 0\n",
        "        elif placement_type == 1:\n",
        "            start_row = int((dst_height - src_height) / 2.0)\n",
        "        elif placement_type == 2:\n",
        "            start_row = int(dst_height - src_height)\n",
        "        start_col = 0\n",
        "    else:\n",
        "        dst_height = src_height\n",
        "        dst_width = int(src_height * aspect_ratio)\n",
        "        start_col = int((dst_width - src_width) / 2.0)\n",
        "        if placement_type == 0:\n",
        "            start_col = 0\n",
        "        elif placement_type == 1:\n",
        "            start_col = int((dst_width - src_width) / 2.0)\n",
        "        elif placement_type == 2:\n",
        "            start_col = int(dst_width - src_width)\n",
        "        start_row = 0\n",
        "    dst_img = np.zeros((dst_height, dst_width, n_channels), dtype=np.uint8)\n",
        "    dst_img[start_row:start_row + src_height, start_col:start_col + src_width, :] = src_img\n",
        "    dst_img = cv2.resize(dst_img, (width, height))\n",
        "    if return_factors:\n",
        "        resize_factor = float(height) / float(dst_height)\n",
        "        return dst_img, resize_factor, start_row, start_col\n",
        "    else:\n",
        "        return dst_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FcTV9EUVTrLD"
      },
      "outputs": [],
      "source": [
        "def compute_classification_acc(pred, gt):\n",
        "    assert pred.shape == gt.shape\n",
        "    return (pred == gt).astype(int).sum() / gt.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "468K6vg0TrLD"
      },
      "outputs": [],
      "source": [
        "def compute_iou(b_pred, b_gt):\n",
        "    \"\"\"\n",
        "    :param b_pred: predicted bounding boxes, shape=(n,2,4)\n",
        "    :param b_gt: ground truth bounding boxes, shape=(n,2,4)\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    n = np.shape(b_gt)[0]\n",
        "    L_pred = np.zeros((64, 64))\n",
        "    L_gt = np.zeros((64, 64))\n",
        "    iou = 0.0\n",
        "    for i in range(n):\n",
        "        for b in range(2):\n",
        "            rr, cc = polygon([b_pred[i, b, 0], b_pred[i, b, 0], b_pred[i, b, 2], b_pred[i, b, 2]],\n",
        "                             [b_pred[i, b, 1], b_pred[i, b, 3], b_pred[i, b, 3], b_pred[i, b, 1]], [64, 64])\n",
        "            L_pred[rr, cc] = 1\n",
        "            rr, cc = polygon([b_gt[i, b, 0], b_gt[i, b, 0], b_gt[i, b, 2], b_gt[i, b, 2]],\n",
        "                             [b_gt[i, b, 1], b_gt[i, b, 3], b_gt[i, b, 3], b_gt[i, b, 1]], [64, 64])\n",
        "            L_gt[rr, cc] = 1\n",
        "            iou += (1.0 / (2 * n)) * (np.sum((L_pred + L_gt) == 2) / np.sum((L_pred + L_gt) >= 1))\n",
        "            L_pred[:, :] = 0\n",
        "            L_gt[:, :] = 0\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qlyfiyVETrLE"
      },
      "outputs": [],
      "source": [
        "class A7_Params:\n",
        "    def __init__(self):\n",
        "        # self.prefix = \"test\"\n",
        "        self.prefix = \"valid\"\n",
        "        # self.prefix = \"train\"\n",
        "        self.vis = 0\n",
        "        self.vis_size = (300, 300)\n",
        "        self.show_pred = 1\n",
        "        self.speed_thresh = 10\n",
        "        self.acc_thresh = (0.7, 0.98)\n",
        "        self.iou_thresh = (0.7, 0.98)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5QMGZMgGTrLE"
      },
      "outputs": [],
      "source": [
        "def compute_score(res, thresh):\n",
        "    min_thres, max_thres = thresh\n",
        "    if res < min_thres:\n",
        "        score = 0.0\n",
        "    elif res > max_thres:\n",
        "        score = 100.0\n",
        "    else:\n",
        "        score = float(res - min_thres) / (max_thres - min_thres) * 100\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E1aOYpwkTrLE"
      },
      "outputs": [],
      "source": [
        "def draw_bboxes(img, bbox_1, bbox_2, y1, y2, vis_size):\n",
        "    import cv2\n",
        "    ymin, xmin, ymax, xmax = bbox_1\n",
        "    cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)),\n",
        "                  (0, 255, 0), thickness=1)\n",
        "    cv2.putText(img, '{:d}'.format(y1), (xmin, ymin), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                0.4, (0, 255, 0))\n",
        "    ymin, xmin, ymax, xmax = bbox_2\n",
        "    cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)),\n",
        "                  (255, 0, 0), thickness=1)\n",
        "    cv2.putText(img, '{:d}'.format(y2), (xmin, ymin), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                0.4, (255, 0, 0))\n",
        "    img = resize_ar(img, *vis_size)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTFeB8F6TrLE",
        "outputId": "a1bbbbec-d29b-48d9-9b84-47854b91f853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on 5000 valid images\n",
            "cuda\n",
            "Evaluating: [0/5000 (0%)]\n",
            "\n",
            "Evaluating: [100/5000 (2%)]\n",
            "\n",
            "Evaluating: [200/5000 (4%)]\n",
            "\n",
            "Evaluating: [300/5000 (6%)]\n",
            "\n",
            "Evaluating: [400/5000 (8%)]\n",
            "\n",
            "Evaluating: [500/5000 (10%)]\n",
            "\n",
            "Evaluating: [600/5000 (12%)]\n",
            "\n",
            "Evaluating: [700/5000 (14%)]\n",
            "\n",
            "Evaluating: [800/5000 (16%)]\n",
            "\n",
            "Evaluating: [900/5000 (18%)]\n",
            "\n",
            "Evaluating: [1000/5000 (20%)]\n",
            "\n",
            "Evaluating: [1100/5000 (22%)]\n",
            "\n",
            "Evaluating: [1200/5000 (24%)]\n",
            "\n",
            "Evaluating: [1300/5000 (26%)]\n",
            "\n",
            "Evaluating: [1400/5000 (28%)]\n",
            "\n",
            "Evaluating: [1500/5000 (30%)]\n",
            "\n",
            "Evaluating: [1600/5000 (32%)]\n",
            "\n",
            "Evaluating: [1700/5000 (34%)]\n",
            "\n",
            "Evaluating: [1800/5000 (36%)]\n",
            "\n",
            "Evaluating: [1900/5000 (38%)]\n",
            "\n",
            "Evaluating: [2000/5000 (40%)]\n",
            "\n",
            "Evaluating: [2100/5000 (42%)]\n",
            "\n",
            "Evaluating: [2200/5000 (44%)]\n",
            "\n",
            "Evaluating: [2300/5000 (46%)]\n",
            "\n",
            "Evaluating: [2400/5000 (48%)]\n",
            "\n",
            "Evaluating: [2500/5000 (50%)]\n",
            "\n",
            "Evaluating: [2600/5000 (52%)]\n",
            "\n",
            "Evaluating: [2700/5000 (54%)]\n",
            "\n",
            "Evaluating: [2800/5000 (56%)]\n",
            "\n",
            "Evaluating: [2900/5000 (58%)]\n",
            "\n",
            "Evaluating: [3000/5000 (60%)]\n",
            "\n",
            "Evaluating: [3100/5000 (62%)]\n",
            "\n",
            "Evaluating: [3200/5000 (64%)]\n",
            "\n",
            "Evaluating: [3300/5000 (66%)]\n",
            "\n",
            "Evaluating: [3400/5000 (68%)]\n",
            "\n",
            "Evaluating: [3500/5000 (70%)]\n",
            "\n",
            "Evaluating: [3600/5000 (72%)]\n",
            "\n",
            "Evaluating: [3700/5000 (74%)]\n",
            "\n",
            "Evaluating: [3800/5000 (76%)]\n",
            "\n",
            "Evaluating: [3900/5000 (78%)]\n",
            "\n",
            "Evaluating: [4000/5000 (80%)]\n",
            "\n",
            "Evaluating: [4100/5000 (82%)]\n",
            "\n",
            "Evaluating: [4200/5000 (84%)]\n",
            "\n",
            "Evaluating: [4300/5000 (86%)]\n",
            "\n",
            "Evaluating: [4400/5000 (88%)]\n",
            "\n",
            "Evaluating: [4500/5000 (90%)]\n",
            "\n",
            "Evaluating: [4600/5000 (92%)]\n",
            "\n",
            "Evaluating: [4700/5000 (94%)]\n",
            "\n",
            "Evaluating: [4800/5000 (96%)]\n",
            "\n",
            "Evaluating: [4900/5000 (98%)]\n",
            "\n",
            "Classification Accuracy: 0.981\n",
            "Detection IOU: 0.898\n",
            "Test time: 58.140 seconds\n",
            "Test speed: 86.000 images / second\n",
            "Classification Score: 100.000\n",
            "IOU Score: 70.574\n",
            "Overall Score: 85.287\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    params = A7_Params()\n",
        "    try:\n",
        "        import paramparse\n",
        "    except ImportError:\n",
        "        pass\n",
        "    else:\n",
        "        paramparse.process(params)\n",
        "    prefix = params.prefix\n",
        "    images = np.load(\"/content/gdrive/My Drive/visual_recognition_data/\" + prefix + \"_X.npy\")\n",
        "    gt_classes = np.load(\"/content/gdrive/My Drive/visual_recognition_data/\" + prefix + \"_Y.npy\")\n",
        "    gt_bboxes = np.load(\"/content/gdrive/My Drive/visual_recognition_data/\" + prefix + \"_bboxes.npy\")\n",
        "    n_images = images.shape[0]\n",
        "    print(f'running on {n_images} {prefix} images')\n",
        "    start_t = timeit.default_timer()\n",
        "    pred_classes, pred_bboxes = classify_and_detect(images)\n",
        "    end_t = timeit.default_timer()\n",
        "    test_time = end_t - start_t\n",
        "    assert test_time > 0, \"test_time cannot be 0\"\n",
        "    test_speed = float(n_images) / test_time\n",
        "    acc = compute_classification_acc(pred_classes, gt_classes)\n",
        "    iou = compute_iou(pred_bboxes, gt_bboxes)\n",
        "    acc_score = compute_score(acc, params.acc_thresh)\n",
        "    iou_score = compute_score(iou, params.iou_thresh)\n",
        "    if test_speed < params.speed_thresh:\n",
        "        overall_score = 0\n",
        "    else:\n",
        "        overall_score = (iou_score + acc_score) / 2\n",
        "    print(f\"Classification Accuracy: {acc:.3f}\")\n",
        "    print(f\"Detection IOU: {iou:.3f}\")\n",
        "    print(f\"Test time: {test_time:.3f} seconds\")\n",
        "    print(f\"Test speed: {test_speed:.3f} images / second\")\n",
        "    print(f\"Classification Score: {acc_score:.3f}\")\n",
        "    print(f\"IOU Score: {iou_score:.3f}\")\n",
        "    print(f\"Overall Score: {overall_score:.3f}\")\n",
        "    if params.vis:\n",
        "        import cv2\n",
        "        print('press space to taggle pause after each frame and escape to quit')\n",
        "        pause_after_frame = 1\n",
        "        for img_id in range(n_images):\n",
        "            src_img = images[img_id, ...].squeeze().reshape((64, 64, 3)).astype(np.uint8)\n",
        "            vis_img = np.copy(src_img)\n",
        "            vis_img_det = None\n",
        "            if params.show_pred:\n",
        "                vis_img_det = np.copy(src_img)\n",
        "            bbox_1 = gt_bboxes[img_id, 0, :].squeeze().astype(np.int32)\n",
        "            bbox_2 = gt_bboxes[img_id, 1, :].squeeze().astype(np.int32)\n",
        "            y1, y2 = gt_classes[img_id, ...].squeeze()\n",
        "            gt_classes[img_id, ...].squeeze()\n",
        "            vis_img = draw_bboxes(vis_img, bbox_1, bbox_2, y1, y2, params.vis_size)\n",
        "            if params.show_pred:\n",
        "                bbox_1 = pred_bboxes[img_id, 0, :].squeeze().astype(np.int32)\n",
        "                bbox_2 = pred_bboxes[img_id, 1, :].squeeze().astype(np.int32)\n",
        "                y1, y2 = pred_classes[img_id, ...].squeeze()\n",
        "                gt_classes[img_id, ...].squeeze()\n",
        "                vis_img_det = draw_bboxes(vis_img_det, bbox_1, bbox_2, y1, y2, params.vis_size)\n",
        "                vis_img = np.concatenate((vis_img, vis_img_det), axis=1)\n",
        "            cv2.imshow('vis_img', vis_img)\n",
        "            key = cv2.waitKey(1 - pause_after_frame)\n",
        "            if key == 27:\n",
        "                return\n",
        "            elif key == 32:\n",
        "                pause_after_frame = 1 - pause_after_frame\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}