{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYqF-b6dBoXn"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dL4u1UElBoXo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import timeit\n",
        "from collections import OrderedDict\n",
        "from pprint import pformat\n",
        "from torch import linalg as LA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9QptF5SaomB"
      },
      "source": [
        "Function to compute your base score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gT7V4FBPaSgd"
      },
      "outputs": [],
      "source": [
        "def compute_base_score(acc, min_thres, max_thres):\n",
        "    if acc <= min_thres:\n",
        "        base_score = 0.0\n",
        "    elif acc >= max_thres:\n",
        "        base_score = 100.0\n",
        "    else:\n",
        "        base_score = float(acc - min_thres) / (max_thres - min_thres) \\\n",
        "                     * 100\n",
        "    return base_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHjNnh7mb04e"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SnTVsK8kb1Bt"
      },
      "outputs": [],
      "source": [
        "def compute_runtime_factor(runtime, min_thres, max_thres):\n",
        "    if runtime <= min_thres:\n",
        "        score_factor = 1\n",
        "    elif runtime >= max_thres:\n",
        "        score_factor = 0\n",
        "    else:\n",
        "        score_factor = 0.5\n",
        "\n",
        "    return score_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufBjsZ2Ha8Bx"
      },
      "source": [
        "Function to run your k-NN algorithm and compute its accuracy and runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EoPL_OlYa8ys"
      },
      "outputs": [],
      "source": [
        "def run(x_train, y_train, x_test, y_test, n_classes, device, n_runs):\n",
        "    if device != 'cpu' and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print('Running on GPU: {}'.format(torch.cuda.get_device_name(0)))\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print('Running on CPU')\n",
        "\n",
        "    run_times = []\n",
        "\n",
        "    for i in range(n_runs):\n",
        "        start = timeit.default_timer()\n",
        "        # np.random.seed(0)\n",
        "        predicted_y_test = knn(x_train, y_train, x_test, n_classes, device)\n",
        "        # np.random.seed()\n",
        "        stop = timeit.default_timer()\n",
        "        run_time = stop - start\n",
        "        run_times.append(run_time)\n",
        "\n",
        "        print(f'run {i + 1} : run_time: {run_time}')\n",
        "\n",
        "    assert isinstance(predicted_y_test, np.ndarray), \"predicted test labels must be returned as a numpy array\"\n",
        "\n",
        "    correct_predict = (y_test\n",
        "                       == predicted_y_test).astype(np.int32).sum()\n",
        "    accuracy = float(correct_predict) / len(y_test)\n",
        "\n",
        "    run_time = min(run_times)\n",
        "\n",
        "    print('Correct Predictions: {}/{} total \\tAccuracy: {:5f} \\tTime: {:2f}'.format(correct_predict,\n",
        "                                                                                    len(y_test), accuracy, run_time))\n",
        "    return correct_predict, accuracy, run_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5_lbZASBoXr"
      },
      "source": [
        "TODO: Implement knn here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9yHgmydUBoXr"
      },
      "outputs": [],
      "source": [
        "def knn(x_train, y_train, x_test, n_classes, device):\n",
        "    \"\"\"\n",
        "    x_train: 60000 x 784 matrix: each row is a flattened image of an MNIST digit\n",
        "    y_train: 60000 vector: label for x_train\n",
        "    x_test: 1000 x 784 testing images\n",
        "    n_classes: no. of classes in the classification task\n",
        "    device: pytorch device on which to run the code\n",
        "    return: predicted y_test which is a 1000-sized vector\n",
        "    \"\"\"\n",
        "\n",
        "    # get the shape size\n",
        "    num_row_train, num_col_train = x_train.shape\n",
        "    num_row_test, num_col_test = x_test.shape\n",
        "\n",
        "    # initialize the output y_test\n",
        "    y_test = np.zeros(num_row_test)\n",
        "\n",
        "    # convert to float type\n",
        "    x_test = x_test.astype(np.float32)\n",
        "    x_train = x_train.astype(np.float32)\n",
        "\n",
        "    # Convert from numpy to pytorch tensor\n",
        "    # Move the data to gpu\n",
        "    x_test_tt = torch.from_numpy(x_test).to(device)\n",
        "    x_train_tt = torch.from_numpy(x_train).to(device)\n",
        "    distance = torch.zeros(num_row_train).to(device)\n",
        "\n",
        "    # For every test data point, do classification\n",
        "    for i in list(range(0, num_row_test)):\n",
        "      \n",
        "      distance_vector = x_train_tt - x_test_tt[i].repeat(num_row_train, 1)\n",
        "      distance = LA.norm(distance_vector, dim=1)\n",
        "      \n",
        "      dist, distIndex = torch.topk(distance, 3, largest=False)\n",
        "      \n",
        "      closestY = torch.zeros(3)\n",
        "\n",
        "      # get the labels of closest data points\n",
        "      for k in list(range(0, 3)):\n",
        "        closestY[k] = y_train[distIndex[k]]\n",
        "\n",
        "      # use the mode label\n",
        "      mode, modeIndex = torch.mode(closestY)\n",
        "      y_test[i] = mode\n",
        "\n",
        "    return y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkZ_qUyeBoXt"
      },
      "source": [
        "Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "skv5jrRCBoXu"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    min_acc_thres = 0.84\n",
        "    max_acc_thres = 0.94\n",
        "\n",
        "    min_runtime_thres = 12\n",
        "    max_runtime_thres = 24\n",
        "\n",
        "    n_runs = 5\n",
        "\n",
        "    n_classes = 10\n",
        "    # change to cpu to run on CPU\n",
        "    device = 'gpu'\n",
        "\n",
        "    mnist_train = datasets.MNIST('data', train=True, download=True,\n",
        "                                 transform=transforms.Compose([\n",
        "                                     transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                                 ])\n",
        "                                 )\n",
        "    mnist_test = datasets.MNIST('data', train=False, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                                ])\n",
        "                                )\n",
        "    # convert pytorch tensors to numpy arrays\n",
        "    (x_train, y_train) = (mnist_train.data.cpu().numpy(), mnist_train.targets.cpu().numpy())\n",
        "    (x_valid, y_valid) = (mnist_test.data.cpu().numpy(), mnist_test.targets.cpu().numpy())\n",
        "\n",
        "    # flatten 28x28 images into 784 sized vectors\n",
        "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], -1)\n",
        "\n",
        "    # You may want to use a smaller training set to save time when debugging\n",
        "    # i.e.: Put something like:\n",
        "    # (x_train, y_train) = (x_train[:5000], y_train[:5000])\n",
        "\n",
        "    # For this assignment, we only test on the first 1000 samples of the test set\n",
        "    (x_valid, y_valid) = (x_valid[:1000], y_valid[:1000])\n",
        "\n",
        "    print(\"Dimension of dataset: \")\n",
        "    print(\"Train:\", x_train.shape, y_train.shape, \"\\nTest:\", x_valid.shape, y_valid.shape)\n",
        "\n",
        "    (correct_predict, accuracy, run_time) = run(x_train, y_train, x_valid, y_valid, n_classes, device, n_runs)\n",
        "    base_score = compute_base_score(accuracy, min_acc_thres, max_acc_thres)\n",
        "\n",
        "    runtime_factor = compute_runtime_factor(run_time, min_runtime_thres, max_runtime_thres)\n",
        "\n",
        "    overall_score = base_score * runtime_factor\n",
        "\n",
        "    result = OrderedDict(correct_predict=correct_predict,\n",
        "                         accuracy=accuracy,\n",
        "                         run_time=run_time,\n",
        "                         base_score=base_score,\n",
        "                         overall_score=overall_score\n",
        "                         )\n",
        "\n",
        "    with open('result.txt', 'w') as f:\n",
        "        f.writelines(pformat(result, indent=4))\n",
        "\n",
        "    print(pformat(result, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLT1ozE5dVcN"
      },
      "source": [
        "Call the main function. You can only run this after filling the _knn_ function above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_fduP2yXBoXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1f9107-6250-4e7a-e43d-3f64f17fe0ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of dataset: \n",
            "Train: (60000, 784) (60000,) \n",
            "Test: (1000, 784) (1000,)\n",
            "Running on GPU: Tesla T4\n",
            "run 1 : run_time: 4.226465571999938\n",
            "run 2 : run_time: 4.20017830200004\n",
            "run 3 : run_time: 4.204567190000034\n",
            "run 4 : run_time: 4.197855642000036\n",
            "run 5 : run_time: 4.208544285000016\n",
            "Correct Predictions: 962/1000 total \tAccuracy: 0.962000 \tTime: 4.197856\n",
            "OrderedDict([   ('correct_predict', 962),\n",
            "                ('accuracy', 0.962),\n",
            "                ('run_time', 4.197855642000036),\n",
            "                ('base_score', 100.0),\n",
            "                ('overall_score', 100.0)])\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}